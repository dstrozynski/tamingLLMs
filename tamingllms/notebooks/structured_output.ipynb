{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrestling with Structured Output\n",
    "\n",
    "## The Structured Output Challenges\n",
    "\n",
    "Large language models (LLMs) excel at generating human-like text, but they often struggle to produce output in a structured format consistently. This poses a significant challenge when we need LLMs to generate data that can be easily processed by other systems, such as databases, APIs, or other software applications.  \n",
    "\n",
    "Sometimes, even with a well-crafted prompt, an LLM might produce an unstructured response when a structured one is expected. This can be particularly challenging when integrating LLMs into systems that require specific data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt expecting a structured JSON response\n",
    "MAX_LENGTH = 10000\n",
    "with open('../data/apple.txt', 'r') as file:\n",
    "    sec_filing = file.read() \n",
    "prompt = f\"\"\"\n",
    "Generate a two-person discussion about the key financial data from the following text in JSON format.\n",
    "TEXT: {sec_filing[:MAX_LENGTH]}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Wow, Apple Inc. seems to have a lot of different products and services they offer. It's interesting to see the breakdown of their revenue streams in their Form 10-K.\n",
      "\n",
      "Person 2: Absolutely, they have a diverse portfolio with iPhones, Macs, iPads, wearables, and even services. It's impressive to see how they have capitalized on different technology trends.\n",
      "\n",
      "Person 1: I noticed that they have a large market value of over $2.6 trillion as of March 29, 2024. That's a huge amount, and it shows the confidence investors have in the company.\n",
      "\n",
      "Person 2: Definitely, that's a significant figure. It's also good to see that they are complying with all the required SEC regulations and filing their reports in a timely manner.\n",
      "\n",
      "Person 1: Yes, it's crucial for investors to have access to accurate and up-to-date financial information. It helps in making informed decisions about their investments in the company.\n",
      "\n",
      "Person 2: Absolutely, transparency and compliance with regulations are key in the financial industry. It's good to see that Apple Inc. is taking those aspects seriously.\n"
     ]
    }
   ],
   "source": [
    "response_content = response.choices[0].message.content\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def is_json(myjson):\n",
    "  try:\n",
    "    json.loads(myjson)\n",
    "  except ValueError as e:\n",
    "    return False\n",
    "  return True\n",
    "\n",
    "is_json(response_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, despite the prompt clearly asking for a JSON object, the LLM generates a natural language sentence instead. This highlights the inconsistency and unpredictability of LLMs when it comes to producing structured output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Obtaining structured output from LLMs presents several significant challenges:\n",
    "\n",
    "* **Inconsistency**: LLMs often produce unpredictable results, sometimes generating well-structured output and other times deviating from the expected format.\n",
    "* **Lack of Type Safety**: LLMs do not inherently understand data types, which can lead to errors when their output is integrated with systems requiring specific data formats.\n",
    "* **Prompt Engineering Complexity**: Crafting prompts that effectively guide LLMs to produce the correct structured output is complex and requires extensive experimentation.\n",
    "\n",
    "## Solutions\n",
    "\n",
    "Several strategies and tools can be employed to address the challenges of structured output from LLMs.\n",
    "\n",
    "### Strategies\n",
    "\n",
    "* **Schema Guidance**: Providing the LLM with a clear schema or blueprint of the desired output structure helps to constrain its generation and improve consistency. This can be achieved by using tools like Pydantic to define the expected data structure and then using that definition to guide the LLM's output. \n",
    "* **Output Parsing**: When LLMs don't natively support structured output, parsing their text output using techniques like regular expressions or dedicated parsing libraries can extract the desired information. For example, you can use regular expressions to extract specific patterns from the LLM's output, or you can use libraries like Pydantic to parse the output into structured data objects.\n",
    "* **Type Enforcement**: Using tools that enforce data types, such as Pydantic in Python, can ensure that the LLM output adheres to the required data formats. This can help to prevent errors when integrating the LLM's output with other systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Shot Prompts\n",
    "\n",
    "In one-shot prompting, you provide a single example of the desired output format within the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a two-person discussion about the key financial data from the following text in JSON format.\n",
    "\n",
    "<JSON_FORMAT>\n",
    "{{\n",
    "   \"Person1\": {{\n",
    "     \"name\": \"Alice\",\n",
    "     \"statement\": \"The revenue for Q1 has increased by 20% compared to last year.\"\n",
    "   }},\n",
    "   \"Person2\": {{\n",
    "     \"name\": \"Bob\",\n",
    "     \"statement\": \"That's great news! What about the net profit margin?\"\n",
    "   }}\n",
    "}}\n",
    "</JSON_FORMAT>\n",
    "\n",
    "TEXT: {sec_filing[:MAX_LENGTH]}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"Person1\": {\n",
      "     \"name\": \"Alice\",\n",
      "     \"statement\": \"The revenue for Q1 has increased by 20% compared to last year.\"\n",
      "   },\n",
      "   \"Person2\": {\n",
      "     \"name\": \"Bob\",\n",
      "     \"statement\": \"That's great news! What about the net profit margin?\"\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_content = response.choices[0].message.content\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_json(response_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Output with Provider-Specific APIs\n",
    "\n",
    "Simple techniques such as one-shot prompting can lead to material improvements though may not be sufficient for complex (e.g. nested) structures and / or when the model's output needs to be restricted to a specific set of options or types.\n",
    "\n",
    "Provider-specific APIs can offer ways to handle those challenges. For example, OpenAI's API offers features specifically designed for generating JSON output or structured outputs, in general.\n",
    "\n",
    "**JSON Mode**\n",
    "\n",
    "JSON mode is a feature provided by some LLM APIs, such as OpenAI's, that allows the model to generate output in JSON format. This is particularly useful when you need structured data as a result, such as when parsing the output programmatically or integrating it with other systems that require JSON input.\n",
    "\n",
    "When using JSON mode, you must always instruct the model to produce JSON via some message in the conversation, for example via your system message. If you don't include an explicit instruction to generate JSON, the model may generate an unending stream of whitespace and the request may run continually until it reaches the token limit. To help ensure you don't forget, the API will throw an error if the string \"JSON\" does not appear somewhere in the context.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a two-person discussion about the key financial data from the following text in JSON format.\n",
    "TEXT: {sec_filing[:MAX_LENGTH]}\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "response_format = { \"type\": \"json_object\" }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"person1\": \"I see that Apple Inc. reported a total market value of approximately $2,628,553,000,000 held by non-affiliates as of March 29, 2024. That's a significant amount!\",\n",
      "  \"person2\": \"Yes, it definitely shows the scale and value of the company in the market. It's impressive to see the sheer size of the market value.\",\n",
      "  \"person1\": \"Also, they mentioned having 15,115,823,000 shares of common stock issued and outstanding as of October 18, 2024. That's a large number of shares circulating in the market.\",\n",
      "  \"person2\": \"Absolutely, the number of shares outstanding plays a crucial role in determining the company's market capitalization and investor interest.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_content = response.choices[0].message.content\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_json(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON mode will not guarantee the output matches any specific schema, only that it is valid and parses without errors. For that purpose, we can leverage a new feature some modern LLM API offer called \"Structured Outputs\" to ensure the output data matches a target schema/typing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Structured Output Mode**\n",
    "\n",
    "Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied JSON Schema, so you don't need to worry about the model omitting a required key, or hallucinating an invalid enum value.\n",
    "\n",
    "Some benefits of Structured Outputs include:\n",
    "- **Reliable type-safety**: No need to validate or retry incorrectly formatted responses.\n",
    "- **Explicit refusals**: Safety-based model refusals are now programmatically detectable.\n",
    "- **Simpler prompting**: No need for strongly worded prompts to achieve consistent formatting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a Python example demonstrating how to use the OpenAI API to generate a structured output in the form of a two-person conversation discussing financial statements from an input SEC filing. This example uses the `response_format` parameter within the OpenAI API call. This functionality is supported by GPT-4o models, specifically `gpt-4o-mini-2024-07-18`, `gpt-4o-2024-08-06`, and later versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class SECExtraction(BaseModel):\n",
    "    mentioned_entities: list[str]\n",
    "    mentioned_places: list[str]\n",
    "\n",
    "def extract_from_sec_filing(sec_filing_text: str) -> SECExtraction:\n",
    "    \"\"\"\n",
    "    Extracts structured data from an input SEC filing text.\n",
    "    \"\"\"\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are an expert at structured data extraction. You will be given unstructured text from a SEC filing and extracted names of mentioned entities and places and should convert the response into the given structure.\"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": sec_filing_text}\n",
    "        ],\n",
    "        response_format=SECExtraction\n",
    "    )\n",
    "    return completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "*   **Data Structures:** The code defines two Pydantic models, `DialogueTurn` and `FinancialStatementDiscussion`, to represent the structured output of the conversation. These models provide type hints and structure for the conversation.\n",
    "*   **API Interaction:** The `generate_conversation` function uses the OpenAI client to send a chat completion request to the `gpt-4o-2024-08-06` model. The prompt instructs the model to simulate a dialogue about financial statements. The `response_format` is set to `FinancialStatementDiscussion`, ensuring the response conforms to the Pydantic model.\n",
    "*   **Output Processing:** The returned response is parsed into the `FinancialStatementDiscussion` model. The code then iterates through the dialogue turns and prints the speaker and content of each turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = extract_from_sec_filing(sec_filing[:MAX_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities: ['Apple Inc.', 'The Nasdaq Stock Market LLC']\n",
      "Extracted places: ['Washington, D.C.', 'California', 'Cupertino, California']\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracted entities:\", conversation.mentioned_entities)\n",
    "print(\"Extracted places:\", conversation.mentioned_places)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benefits**\n",
    "\n",
    "*   **Structured Output:** The use of Pydantic models and the `response_format` parameter enforces the structure of the model's output, making it more reliable and easier to process.\n",
    "*   **Schema Adherence:**  Structured Outputs in OpenAI API guarantee that the response adheres to the provided schema.\n",
    "\n",
    "This structured approach improves the reliability and usability of your application by ensuring consistent, predictable output from the OpenAI API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain\n",
    "\n",
    "LangChain is a framework designed to simplify the development of LLM applications. It offers several tools for parsing structured output, including:\n",
    "\n",
    "* **`with_structured_output`**: This method is used with LLMs that support structured output APIs, allowing you to enforce a schema directly within the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlines\n",
    "\n",
    "Outlines is a library specifically focused on structured text generation from LLMs.  It provides several powerful features:\n",
    "\n",
    "* **Multiple Choice Generation**: Restrict the LLM output to a predefined set of options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Solutions\n",
    "\n",
    "* **Simplicity vs. Control**: One-shot prompts are simple but offer limited control.  Dedicated tools like Gemini's structured output features, LangChain, and Outlines provide greater control but might have a steeper learning curve.\n",
    "* **Native LLM Support**:  `with_structured_output` in LangChain relies on the LLM having built-in support for structured output APIs. Other methods, like parsing or using Outlines, are more broadly applicable.\n",
    "* **Flexibility**:  Outlines and LangChain's  `StructuredOutputParser`  offer the most flexibility for defining custom output structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "\n",
    "* **Clear Schema Definition**: Define the desired output structure clearly, using schemas, types, or grammars as appropriate. This ensures the LLM knows exactly what format is expected.\n",
    "* **Descriptive Naming**: Use meaningful names for fields and elements in your schema. This makes the output more understandable and easier to work with.\n",
    "* **Detailed Prompting**: Guide the LLM with well-crafted prompts that include examples and clear instructions.  A well-structured prompt improves the chances of getting the desired output.\n",
    "* **Error Handling**: Implement mechanisms to handle cases where the LLM deviates from the expected structure. LLMs are not perfect, so having error handling ensures your application remains robust.\n",
    "* **Testing and Iteration**: Thoroughly test your structured output generation process and refine your prompts and schemas based on the results. Continuous testing and refinement are key to achieving reliable structured output.\n",
    "* **Structured Response**: If you want to structure the model's output when it responds to the user, then you should consider using a structured response_format (e.g. JSON format).\n",
    "* **Function Calling**: If you are connecting the model to tools, functions, data, etc. in your system, then you should use a typed structured output.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Extracting structured output from LLMs is crucial for integrating them into real-world applications. By understanding the challenges and employing appropriate strategies and tools, developers can improve the reliability and usability of LLM-powered systems, unlocking their potential to automate complex tasks and generate valuable insights. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
