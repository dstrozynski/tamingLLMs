{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42586c69",
   "metadata": {},
   "source": [
    "(intro)=\n",
    "# Introduction\n",
    "\n",
    "```{epigraph}\n",
    "I am always doing that which I cannot do, in order that I may learn how to do it.\n",
    "\n",
    "-- Pablo Picasso\n",
    "```\n",
    "```{contents}\n",
    "```\n",
    "\n",
    "## Core Challenges We'll Address\n",
    "\n",
    "In recent years, Large Language Models (LLMs) have emerged as a transformative force in technology, promising to revolutionize how we build products and interact with computers. From ChatGPT to GitHub Copilot, Claude Artifacts, cursor.com, replit, and others, these systems have captured the public imagination and sparked a gold rush of AI-powered applications. However, beneath the surface of this technological revolution lies a complex landscape of challenges that practitioners must navigate. \n",
    "\n",
    "As we'll explore in this book, the engineering effort required to manage these challenges - from handling non-deterministic outputs to preventing hallucinations - cannot be overstated. While the potential of LLM technology remains compelling, understanding and addressing the hidden costs and complexities of building reliable LLM-powered systems will enable us to fully harness their transformative impact. Fortunately, a growing ecosystem of open source solutions and best practices have emerged to help tackle these limitations. Ranging from model families such as Llama and Mistral, to frameworks such as Ollama and LangChain, packages such as outlines and promptfoo, formats such as llamafile and /llms.txt and hubs like HuggingFace, practitioners will be equipped with a set of battle-tested tools and solutions for overcoming LLM limitations to develop, test and launch robust LLM-based applications.\n",
    "\n",
    "While the capabilities of LLMs are indeed remarkable, the prevailing narrative often glosses over fundamental problems that engineers, product managers, and organizations face when building real-world applications. This book aims to bridge that gap, offering a practical, clear-eyed examination of the pitfalls and challenges in working with LLMs while providing a set of open source solutions to overcome them.\n",
    "\n",
    "Throughout this book, we'll tackle the following (non-exhaustive) list of critical challenges:\n",
    "\n",
    "1. **Structural (un)Reliability**: LLMs struggle to maintain consistent output formats, complicating their integration into larger systems and making error handling more complex.\n",
    "\n",
    "2. **Size and Length Constraints**: LLMs have strict token limits for both inputs and outputs, requiring careful chunking and management strategies to handle long-form content effectively.\n",
    "\n",
    "3. **Testing Complexity**: Traditional software testing methodologies break down when dealing with non-deterministic and generative systems, requiring new approaches.\n",
    "\n",
    "4. **Hallucination Management**: These models can generate plausible-sounding but entirely fabricated information, creating significant risks for production applications.\n",
    "\n",
    "5. **Safety and Security**: LLMs can generate harmful, biased, or inappropriate content, requiring robust safeguards and monitoring systems to ensure safe deployment.\n",
    "\n",
    "6. **Cost Optimization**: The computational and financial costs of operating LLM-based systems can quickly become prohibitive without careful management, observability and optimization.\n",
    "\n",
    "7. **Vendor Lock-in**: Cloud-based LLM providers can create significant dependencies and lock-in through their proprietary APIs and infrastructure, making it difficult to switch providers or self-host solutions.\n",
    "\n",
    "\n",
    "## A Practical Approach\n",
    "\n",
    "This book takes a hands-on approach to these challenges, providing:\n",
    "\n",
    "- Concrete Python examples that you can run and modify\n",
    "- Real-world scenarios and solutions\n",
    "- Testing strategies and best practices\n",
    "- Cost optimization techniques\n",
    "- Integration patterns and anti-patterns\n",
    "\n",
    "## A Note on Perspective\n",
    "\n",
    "While this book takes a critical look at LLM limitations, our goal is not to discourage their use but to enable more robust and reliable implementations. By understanding these challenges upfront, you'll be better equipped to build systems that leverage LLMs effectively while avoiding common pitfalls.\n",
    "\n",
    "The current discourse around LLMs tends toward extremesâ€”either uncritical enthusiasm or wholesale dismissal. This book takes a different approach:\n",
    "\n",
    "- **Practical Implementation Focus**: Rather than theoretical capabilities, we examine real-world challenges and their solutions.\n",
    "- **Code-First Learning**: Every concept is illustrated with executable Python examples, enabling immediate practical application.\n",
    "- **Critical Analysis**: We provide a balanced examination of both capabilities and limitations, helping readers make informed decisions about LLM integration.\n",
    "\n",
    "## Who This Book Is For\n",
    "\n",
    "This book is inteded to Software Developers taking their first steps with Large Language Models. It provides critical insights into the practical challenges of LLM implementation, along with guidance on leveraging open source tools and frameworks to avoid common pitfalls that could derail projects. The goal is to help developers understand and address these challenges early, before they become costly problems too late in the software development lifecycle. \n",
    "\n",
    "A broader audience for this book includes:\n",
    "\n",
    "- Technical Product Managers leading AI initiatives\n",
    "- Technical Leaders making architectural decisions\n",
    "- Anyone seeking to understand the practical challenges of working with LLMs\n",
    "\n",
    "Typical job roles:\n",
    "\n",
    "- Software Engineers building AI-powered platforms\n",
    "- Backend Developers integrating LLMs into existing systems\n",
    "- ML Engineers transitioning to LLM implementation\n",
    "- Technical Leads making architectural decisions\n",
    "- Product Managers overseeing GenAI initiatives\n",
    "\n",
    "Reader motivation:\n",
    "\n",
    "- Need to build reliable, production-ready LLM applications\n",
    "- Desire to understand and overcome common LLM implementation challenges\n",
    "- Requirement to optimize costs and performance\n",
    "- Need to ensure safety and reliability in LLM-powered systems\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "\n",
    "After reading this book, the reader will understand critical LLM limitations and their implications and have practical experience on recommended open source tools and frameworks to help navigate common LLM pitfalls. The reader will be able to:\n",
    "\n",
    "- Implement effective strategies for managing LLMs limitations\n",
    "- Build reliable LLM-powered applications\n",
    "- Create robust testing frameworks for LLM-based systems\n",
    "- Deploy proper LLM safeguards\n",
    "- Make realistic effort estimations for LLM-based projects\n",
    "- Understand the hidden complexities that impact development timelines\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To make the most of this book, you should have:\n",
    "\n",
    "- Basic Python programming experience\n",
    "- Basic knowledge of LLMs and their capabilities\n",
    "- Introductory experience with LangChain (e.g. Chat Models and Prompt Templates)\n",
    "- Access to and basic knowledge of LLM APIs (OpenAI, Anthropic, or similar)\n",
    "- A desire to build reliable, production-grade LLM-powered products\n",
    "\n",
    "\n",
    "## Setting Up Your Environment\n",
    "\n",
    "Before diving into the examples in this book, you'll need to set up your development environment. Here's how to get started:\n",
    "\n",
    "### Python Environment Setup\n",
    "```bash\n",
    "# Create and activate a virtual environment\n",
    "python -m venv llm-book-env\n",
    "source llm-book-env/bin/activate  # On Windows, use: llm-book-env\\Scripts\\activate\n",
    "\n",
    "# Install required packages\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### API Keys Configuration\n",
    "1. Create a `.env` file in the root directory of the project.\n",
    "2. Add your API keys and other sensitive information to the `.env` file. For example:\n",
    "\n",
    "   ```bash\n",
    "   OPENAI_API_KEY=your_openai_api_key_here\n",
    "   ```\n",
    "\n",
    "```{note}\n",
    "Never share your `.env` file or commit it to version control. It contains sensitive information that should be kept private.\n",
    "```\n",
    "\n",
    "### Code Repository\n",
    "Clone the book's companion repository:\n",
    "```bash\n",
    "git clone https://github.com/souzatharsis/tamingllms.git\n",
    "cd tamingllms\n",
    "```\n",
    "\n",
    "### Troubleshooting Common Issues\n",
    "- If you encounter API rate limits, consider using smaller examples or implementing retry logic\n",
    "- For package conflicts, try creating a fresh virtual environment or use a package manager like `poetry`\n",
    "- Check the book's repository issues page for known problems and solutions\n",
    "\n",
    "Now that your environment is set up, let's begin our exploration of LLM challenges.\n",
    "\n",
    "## About the Author(s)\n",
    "\n",
    "Dr. Tharsis Souza is a computer scientist and product leader specializing in AI-based products. He is a Lecturer at Columbia University's Master of Science program in Applied Analytics, Head of Product, Equities at Citadel, and former Senior VP at Two Sigma Investments.\n",
    "\n",
    "With over 15 years of experience delivering technology products across startups and Fortune 500 companies globally, Dr. Souza is also an author of numerous scholarly publications and is a frequent speaker at academic and business conferences. Grounded on academic background and drawing from practical experience building and scaling up products powered by language models at early-stage startups, major institutions as well as advising non-profit organizations, and contributing to open source projects, he brings a unique perspective on bridging the gap between LLMs promised potential and their practical limitations using open source tools to enable the next generation of AI-powered products.\n",
    "\n",
    "Dr. Tharsis holds a Ph.D. in Computer Science from UCL, University of London following an M.Phil. and M.Sc. in Computer Science and a B.Sc. in Computer Engineering."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}