<!DOCTYPE html>
<html  lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

      <title>Introduction</title>
    
          <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
          <link rel="stylesheet" href="../_static/theme.css " type="text/css" />
          <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
          <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
          <link rel="stylesheet" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
          <link rel="stylesheet" href="../_static/sphinx-thebe.css" type="text/css" />
          <link rel="stylesheet" href="../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" type="text/css" />
      
      <!-- sphinx script_files -->
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/scripts/sphinx-book-theme.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script src="../_static/design-tabs.js"></script>
        <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
        <script async="async" src="../_static/sphinx-thebe.js"></script>

      
      <!-- bundled in js (rollup iife) -->
      <!-- <script src="../_static/theme-vendors.js"></script> -->
      <script src="../_static/theme.js" defer></script>
      <link rel="canonical" href="https://souzatharsis.github.io/tamingllms/markdown/intro.html" />
    
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Output Size Limitations" href="../notebooks/output_size_limit.html" />
  <link rel="prev" title="Taming Large Language Models" href="toc.html" /> 
  </head>

  <body>
    <div id="app">
    <div class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="toc.html" class="home-link">
    
      <span class="site-name">tamingLLMs</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="../search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="toc.html#taming-large-language-models">taming large language models</a></span>
      </p>
      <ul class="current">
        
          <li class="toctree-l1 current">
            
              <a href="#" class="reference internal current">Introduction</a>
            

            
              <ul>
                
                  <li class="toctree-l2"><a href="#core-challenges-we-ll-address" class="reference internal">Core Challenges We’ll Address</a></li>
                
                  <li class="toctree-l2"><a href="#a-note-on-perspective" class="reference internal">A Note on Perspective</a></li>
                
                  <li class="toctree-l2"><a href="#a-practical-approach" class="reference internal">A Practical Approach</a></li>
                
                  <li class="toctree-l2"><a href="#who-this-book-is-for" class="reference internal">Who This Book Is For</a></li>
                
                  <li class="toctree-l2"><a href="#prerequisites" class="reference internal">Prerequisites</a></li>
                
                  <li class="toctree-l2"><a href="#setting-up-your-environment" class="reference internal">Setting Up Your Environment</a></li>
                
              </ul>
            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../notebooks/output_size_limit.html" class="reference internal ">Output Size Limitations</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../notebooks/structured_output.html" class="reference internal ">Wrestling with Structured Output</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../notebooks/nondeterminism.html" class="reference internal ">Non-determinism & Evals</a>
            

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="toc.html">Docs</a> &raquo;</li>
    
    <li>Introduction</li>
  </ul>
  

  <ul class="page-nav">
  <li class="prev">
    <a href="toc.html"
       title="previous chapter">← Taming Large Language Models</a>
  </li>
  <li class="next">
    <a href="../notebooks/output_size_limit.html"
       title="next chapter">Output Size Limitations →</a>
  </li>
</ul>
  
</div>
<hr>
          <div class="content" role="main" v-pre>
            
  <section class="tex2jax_ignore mathjax_ignore" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h1>
<p>In recent years, Large Language Models (LLMs) have emerged as a transformative force in technology, promising to revolutionize how we build products and interact with computers. From ChatGPT to GitHub Copilot, Claude Artifacts, <a class="reference external" href="http://cursor.com">cursor.com</a>, replit, and others, these systems have captured the public imagination and sparked a gold rush of AI-powered applications. However, beneath the surface of this technological revolution lies a complex landscape of challenges that practitioners must navigate.</p>
<p>As we’ll explore in this book, the engineering effort required to manage these challenges - from handling non-deterministic outputs to preventing hallucinations - cannot be overstated. While the potential of LLM technology remains compelling, understanding and addressing the hidden costs and complexities of building reliable LLM-powered systems will enable us to fully harness their transformative impact.</p>
<section id="core-challenges-we-ll-address">
<h2>Core Challenges We’ll Address<a class="headerlink" href="#core-challenges-we-ll-address" title="Permalink to this heading">¶</a></h2>
<p>While the capabilities of LLMs are indeed remarkable, the prevailing narrative often glosses over fundamental problems that engineers, product managers, and organizations face when building real-world applications. This book aims to bridge that gap, offering a practical, clear-eyed examination of the pitfalls and challenges in working with LLMs.</p>
<p>Throughout this book, we’ll tackle the following (non-exhaustive) list of critical challenges:</p>
<ol class="arabic simple">
<li><p><strong>Non-deterministic Behavior</strong>: Unlike traditional software systems, LLMs can produce different outputs for identical inputs, making testing and reliability assurance particularly challenging.</p></li>
<li><p><strong>Structural (un)Reliability</strong>: LLMs struggle to maintain consistent output formats, complicating their integration into larger systems and making error handling more complex.</p></li>
<li><p><strong>Hallucination Management</strong>: These models can generate plausible-sounding but entirely fabricated information, creating significant risks for production applications.</p></li>
<li><p><strong>Cost Optimization</strong>: The computational and financial costs of operating LLM-based systems can quickly become prohibitive without careful optimization.</p></li>
<li><p><strong>Testing Complexity</strong>: Traditional testing methodologies break down when dealing with non-deterministic systems, requiring new approaches.</p></li>
</ol>
</section>
<section id="a-note-on-perspective">
<h2>A Note on Perspective<a class="headerlink" href="#a-note-on-perspective" title="Permalink to this heading">¶</a></h2>
<p>While this book takes a critical look at LLM limitations, our goal is not to discourage their use but to enable more robust and reliable implementations. By understanding these challenges upfront, you’ll be better equipped to build systems that leverage LLMs effectively while avoiding common pitfalls.</p>
<p>The current discourse around LLMs tends toward extremes—either uncritical enthusiasm or wholesale dismissal. This book takes a different approach:</p>
<ul class="simple">
<li><p><strong>Practical Implementation Focus</strong>: Rather than theoretical capabilities, we examine real-world challenges and their solutions.</p></li>
<li><p><strong>Code-First Learning</strong>: Every concept is illustrated with executable Python examples, enabling immediate practical application.</p></li>
<li><p><strong>Critical Analysis</strong>: We provide a balanced examination of both capabilities and limitations, helping readers make informed decisions about LLM integration.</p></li>
</ul>
</section>
<section id="a-practical-approach">
<h2>A Practical Approach<a class="headerlink" href="#a-practical-approach" title="Permalink to this heading">¶</a></h2>
<p>This book takes a hands-on approach to these challenges, providing:</p>
<ul class="simple">
<li><p>Concrete Python examples that you can run and modify</p></li>
<li><p>Real-world scenarios and solutions</p></li>
<li><p>Testing strategies and best practices</p></li>
<li><p>Cost optimization techniques</p></li>
<li><p>Integration patterns and anti-patterns</p></li>
</ul>
</section>
<section id="who-this-book-is-for">
<h2>Who This Book Is For<a class="headerlink" href="#who-this-book-is-for" title="Permalink to this heading">¶</a></h2>
<p>This book is designed for:</p>
<ul class="simple">
<li><p>Software Engineers building LLM-powered applications</p></li>
<li><p>Product Managers leading AI initiatives</p></li>
<li><p>Technical Leaders making architectural decisions</p></li>
<li><p>Anyone seeking to understand the practical challenges of working with LLMs</p></li>
</ul>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading">¶</a></h2>
<p>To make the most of this book, you should have:</p>
<ul class="simple">
<li><p>Basic Python programming experience</p></li>
<li><p>Access to and basic knowledge of LLM APIs (OpenAI, Anthropic, or similar)</p></li>
<li><p>A desire to build reliable, production-grade LLM-powered products</p></li>
</ul>
</section>
<section id="setting-up-your-environment">
<h2>Setting Up Your Environment<a class="headerlink" href="#setting-up-your-environment" title="Permalink to this heading">¶</a></h2>
<p>Before diving into the examples in this book, you’ll need to set up your development environment. Here’s how to get started:</p>
<section id="python-environment-setup">
<h3>1. Python Environment Setup<a class="headerlink" href="#python-environment-setup" title="Permalink to this heading">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create and activate a virtual environment</span>
python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>llm-book-env
<span class="nb">source</span><span class="w"> </span>llm-book-env/bin/activate<span class="w">  </span><span class="c1"># On Windows, use: llm-book-env\Scripts\activate</span>

<span class="c1"># Install required packages</span>
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</section>
<section id="api-keys-configuration">
<h3>2. API Keys Configuration<a class="headerlink" href="#api-keys-configuration" title="Permalink to this heading">¶</a></h3>
<p>Set required API keys:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">OPENAI_API_KEY</span><span class="o">=</span>your-openai-key
</pre></div>
</div>
</section>
<section id="code-repository">
<h3>3. Code Repository<a class="headerlink" href="#code-repository" title="Permalink to this heading">¶</a></h3>
<p>Clone the book’s companion repository:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/souzatharsis/tamingllms.git
<span class="nb">cd</span><span class="w"> </span>tamingllms
</pre></div>
</div>
</section>
<section id="troubleshooting-common-issues">
<h3>Troubleshooting Common Issues<a class="headerlink" href="#troubleshooting-common-issues" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>If you encounter API rate limits, consider using smaller examples or implementing retry logic</p></li>
<li><p>For package conflicts, try creating a fresh virtual environment or use a package manager like <code class="docutils literal notranslate"><span class="pre">poetry</span></code></p></li>
<li><p>Check the book’s repository issues page for known problems and solutions</p></li>
</ul>
<p>Now that your environment is set up, let’s begin our exploration of LLM challenges.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./markdown"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
  <li class="prev">
    <a href="toc.html"
       title="previous chapter">← Taming Large Language Models</a>
  </li>
  <li class="next">
    <a href="../notebooks/output_size_limit.html"
       title="next chapter">Output Size Limitations →</a>
  </li>
</ul><div class="footer" role="contentinfo">
      &#169; Copyright Tharsis T. P. Souza, 2024.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 6.2.1 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a> 0.9.1.
</div>
            </div>
          </div>
      </page>
    </div></div>
    
    
  </body>
</html>